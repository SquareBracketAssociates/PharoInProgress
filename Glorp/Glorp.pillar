! Object-Relational Persistence with Glorp

!! Introduction

Working in a live object environment like Pharo is great, you can freely create your domain objects and relate or compose them as you like. Sometimes those objects can be stored in a way that preserves the original design  but sometimes you have to store your objects in a Relational Database Management System (aka ''RDBMS'') which requires you to flatten your objects into related tables managed by the RDBMS.

Such process of mapping object to tables is called ''Object-Relational Mapping'' (''ORM'' for short), and like it or not, it imposes certain constraints in the design of you object model to support its persistence in tables, some models are easier to map into tables than others, the difficulty lies in what is known as ''*Object-Relational Impedance Mismatch>https://en.wikipedia.org/wiki/Object-relational_impedance_mismatch*''.

To work with relational databases Pharo provides a battle-tested ORM created at CampSmalltalk a decade ago and maintained since then, its name is Glorp for ''Generic Lightweight Object-Relational Persistence''. It is usually called both GLORP (all caps, as an accronym), or Glorp (as a proper name).

Glorp is an fully featured ORM which provides you with a handful of features to reduce the ''impedance'' as much as possible; among those features you'll find it saves you from writing SQL queries by hand, managing  transactions that rollback the changes to the objects in you image or commit them to the database, writing simple and complex queries using plain Smalltalk syntax, and other features we will cover in this introduction chapter and in chapter of advanced topics.


!! Installation

!!! Database server
Before installing Glorp you should already have installed the RDBMS of your choice in your machine or a reacheable server, it could be *PostgreSQL>http://postgresql.org*, *MySQL>http://dev.mysql.com/*, *SQLite>http://sqlite.org*, or any other of your preference (as long it is supported). Later in the Concepts section Glorp we will refer to this RDBMS as the ''Platform''.

!!! Database drivers
Along with your working installation of your RDBMS of choice you should have installed in your image the drivers required to connect to the database server.
- Native drivers (written in Pharo, no external dependencies)
--  PostgreSQL
--  MySQL

- UDBC
--  PostgreSQL
--  MySQL
--  SQLite (UFFI)
--  ODBC (UFFI, Windows only)
--  OpenDBX (UFFI)


!!! Glorp Packages

Glorp comes in a few packages you can load using a conventional ''Metacello'' definition. One package is the ==Glorp-Core==, there is a ==Glorp-Tests==

[[[
Metacello new
    project: 'Glorp';
    load

]]]

!!! Running the tests

Having loaded the Database drivers and the Glorp packages, it is recommended to run the unit tests of Glorp, to ensure everything was loaded correctly and it is working properly.

!! Fundamentals

Disclaimer:
Altough GLORP doesn't require you to be a SQL Jedi, it is necessary you understand simple concepts of Relational Databases like Tables, Primary Keys (PKs), Foreign Keys (FKs), indexes, column datatypes; and the lingua franca of most, if not all, relational databases: SQL (for ''Structured Query Language'').

In this section we will describe the core concepts of the Glorp framework and the interaction between them. You can skip it if you already know the concepts or if you want to go straight to the tutorial examples.

!!! Some concepts

As said before, one of the benefits of using Glorp is it saves you from writing the SQL statements required to perform ''data manipulation'' queries like ==SELECT==, ==INSERT==, ==UPDATE==, ==DELETE== and also ''data definition'' queries like ==CREATE TABLE==, ==CREATE CONSTRAINT==, including the option to perform ''sub-queries'' (also know as ==SUB SELECT==) and aggregate functions like ==COUNT==, ==GROUP BY==, without leaving the confort of your Pharo syntax.

!!!!Descriptor System
To achieve the above mentioned features Glorp models all the involved concepts
(like tables, columns, classes, etc.) as first class objects, and then relates
instances of those objects in the ==DescriptorSystem==.
It is the core of a Glorp system, it holds all the Glorp metadata,
like the Tables, Descriptors and Class Models.

By using a separate artifact (in this case, a class) to define all
the metadata of your system you can decouple your business models
from its persistence information.
This separation of concerns is a good practice,
and helps with the maintenance of your code.

Also, having an orthogonal description of your domain objects allows you
to have more than one descriptor for the same business domain class,
this is an important difference with patterns like ''ActiveRecord''
where the persistence metadata is defined in the business domain class,
and you can't reuse the same class for two different
systems using different persistence configurations.

!! A simple example

To put some of the concepts described before into practice,
we will create a ==Person== class and store it into a ==PERSON== database table,
 everything from whitin the Pharo environment.

!!! Our example class

!!!! Class definition
[[[
Object subclass: #Person
	instanceVariableNames: 'id name birthDate'
	classVariableNames: ''
	package: 'Glorp-Book'
]]]

!!!!Instance methods
[[[
Person>>#name: aString
  name := aString

  Person>>#name
      ^name

Person>>#birthDate: aDate
    birthDate := aDate

Person>>#birthDate
    ^birthDate
]]]


As you can see the above created class and methods, doesn't have anything
related with its persistence and doesn't require you to inherit from a
particular class.

All the definitions and mappings are defined in a ==DescriptorSystem==,
and we will create one by subclassing it.

[[[
DescriptorSystem subclass: #GlorpBookDescriptorSystem
	instanceVariableNames: ''
	classVariableNames: ''
	package: 'Glorp-Book'
]]]

We said before that Glorp has a whole metamodel that involves describing the
mapped class, the table(s) where it is going to be mapped and the mapping
itself. To define each one of those, Glorp follows a convention in
the method naming, we will mention the conventions below.

!!!!! Class model
We will start by describing the class ==Person==, and the way to
do it is by defining a method with the pattern ==classModelFor''YourClass'':==.

[[[
GlorpBookDescriptorSystem>>#classModelForPerson: aClassModel
  aClassModel newAttributeNamed: #id.
  aClassModel newAttributeNamed: #fistName.
  aClassModel newAttributeNamed: #lastName.
  aClassModel newAttributeNamed: #birthDate.
]]]

!!!!! Table
This class will be stored in a single table (which is the usual case), and we
will provide the description of the table in a similar way as with the class
model, in this case by following the ==tableFor''YOURTABLE''== convention.
Please notice the upper case of the table name.

[[[caption=Table model for PERSON table
GlorpBookDescriptorSystem>>#tableForPERSON: aTable
 	(aTable createFieldNamed: 'id' type: platform serial) bePrimaryKey.
	aTable createFieldNamed: 'firstName' type: (platform varChar: 100).
  aTable createFieldNamed: 'lastName' type: (platform varChar: 100).
  aTable createFieldNamed: 'birthDate' type: platform date.
]]]

!!!!! Descriptor (aka ''Mapping'')
Once we have the class model and the table object, we will define the mappings
between the class attributes and the table fields.
In this simple example we will use a ==DirectMapping==, which is a class of
mapping that takes the value in the column and assigns it to the attribute,
and vice versa.

[[[
GlorpBookDescriptorSystem>>#descriptorForPerson: aDescriptor
  | table |
  table := self tableNamed: 'PERSON'.
  aDescriptor table: table.
  (aDescriptor newMapping: DirectMapping)
    from: #id
    to: (table fieldNamed: 'id').
  (aDescriptor newMapping: DirectMapping)
    from: #firstName
    to: (table fieldNamed: 'firstName').
  (aDescriptor newMapping: DirectMapping)
      from: #lastName
      to: (table fieldNamed: 'lastName').
  (aDescriptor newMapping: DirectMapping)
    from: #birthDate
    to: (table fieldNamed: 'birthDate')
]]]

In the above method we can see how the the descriptor ''links'' the class
attribute to the field name.

Altough verbose and maybe not visible in this simple example, here lies the
power of the Glorp orthogonal description system, you describe everything
and then link all the parts the way you want without modifying your doimain
object.

!!! Creating the tables

Assuming we haven't created the database tables externally, Glorp's metamodel
allows you to perform DDL (''Data Definition Language'') commands such as
==CREATE TABLE== or ==CREATE CONSTRAINT== (among others) using plain
Smalltalk objects, and it even can determine when to run those.

But in order to that we must first connect to the database,
and we will explain how to it in the following pages.

We're using a PostgreSQL server running in the same host
 as our Pharo image. We will then create the Login object and a
 ==DatabaseAccessor== for it to interact with the database.

!!!! Database Accessor
Glorp is programmed to be agnostic of the Smalltalk dialect and
 database driver, to achieve that instead of talking directly to the
 driver it uses an adapter object that acts as an intermediary between
 Glorp and the underlying driver, each database driver requires its
 own subclass of ==DatabaseAccessor==.

We will be using the recommended accessor, which is the ''UDBC'' accessor
 that is compatible with all the drivers supported by
 the ''Unified Database Connectivity'' library.

To define it as the default driver we must evaluate once:

[[[
"Run this once"
UDBCGlorpAccessor beDefaultGlorpDriver
]]]

!!!! The Login
All the information neccesary to connect to the database is defined in the
==Login== object, it is an abstraction for the connection parameters
used to connect to the database server, like the ''Plaform'' used,
hostname, port, username, password, database name and other parameters.

[[[
login := Login new
          database: PostgreSQLPlatform new;
          username: 'postgres';
          password: 'secret';
          connectString: 'localhost_glorpbook'.

]]]

The accessor will require a ==Login== that will use to establish a connection
to the database server specified in the login,
using also the platform specified in it.

[[[
accessor := PharoDatabaseAccessor forLogin: login.
accessor login.
]]]

If everything went fine, then evaluating ==accessor isLoggedIn== should answer
''true''. Another way to test it is performing a basic query like the following
==(accessor basicExecuteSQLString: 'SELECT 3+4') contents first first== should
return ''7'' as the result; and yes, the ==contents first first== is dirty,
but it is not mean to be used this way, we're doing it just to be sure.

Now we're connected to the database we can start interacting with it using
Glorp's objects, and to do that we will require an object that ''orchestrates''
the all the other objects, the ==GlorpSession==. The easiest way to get a
full blown session is to ask the ==DescriptionSystem== passing the a ==Login==
instance as argument.

[[[
session := GlorpBookDescriptorSystem sessionForLogin: login.
session login.
]]]

!!!!! How the parts play together

We'll look into the implementation of ==#sessionForLogin:== to understand
better how each part interacts with each other.
Our ==GlorpBookDescriptorSystem== inherits this implementation.

[[[
DescriptorSystem class>>#sessionForLogin: aGlorpLogin
	| system session |
	system := self forPlatform: aGlorpLogin database.
	session := GlorpSession new.
	session accessor: (DatabaseAccessor forLogin: aGlorpLogin).
	session system: system.
	^session
]]]

First we get a ''system'' instantiating the receiver (in our case
  ==GlorpBookDescriptorSystem==) passing the platform as argument.
  The platform in the ''system'' is important because it will be used to
  generate ''SQL'' code specific for it, using particular syntax and data types.

Then we instantiate a ==GlorpSession== and store it in the ''session'' object.
This ''session'' object is assigned a ==DatabaseAccessor==, it will use such
accessor to communicate to the database, hence the name, but to know what to
send to the ''db'' it needs all the metadata defined in the ''system'' object
defined before.

!!!!!A note about the ''Platform''
In Glorp terminology a Platform is the RDBMS platform.
The abstract class ==Platform==  defines the abstract methods to deal
 with differences of suported data types, test the support of certain features,
 and so on.

!!!! Ready to DDL

Now we have our working ''session'' object, we can perform our ''DDL'' queries
extracting the data from the ''system'' and sending commands to
the ''accessor''. So we just evaluate the following:

[[[
session createTables
]]]

And ''vóilà'', it will send the required commands to the database to create our tables,
sequences, constraints and so on.

!!! Persisting some instances

It is time to put to work all the classes and schema we just created. To do it
we will create and persist a few instances of our example class ==Person==, and
then read some of them back. But before doing it, we'll explain a little bit
how Glorp decides what and when to ''INSERT'', ''UPDATE'' or ''DELETE'' an object.

!!!! Transactions and ''Unit of Work''
If you worked with RDBMS's before, you know you can use transactions that
detachs you from immediate write to the database files, and enable you to
rollback your changes if it is necessary, or do a batch of changes and commit
them all at once.

Glorp provides you with ''automatic'' handling of such database transactions,
but also adds another concept, the ''Unit of work'' (aka ''UOW'' or ''UnitOfWork'').
This ''UnitOfWork'' will keep track of all the persisted objects, enabling
you to commit or rollback changes ""at the object level"" while also maitaining
the database transaction in sync with it.

!!!! Saving the new instances

[[[caption=Saving example instances of Person|language=smalltalk
session inUnitOfWorkDo: [
  {
    (Person new firstName: 'John'; lastName: 'Locke'; birthDate: '1704-08-29' asDate).
    (Person new firstName: 'John'; lastName: 'Malkovich'; birthDate: '1953-12-09' asDate).
    (Person new firstName: 'George'; lastName: 'Lucas'; birthDate: '1944-05-14' asDate)
  } do: [:each | session register: each]
].
]]]

As you can see, we didn't say if the instance needs to be inserted or updated,
nor we specify an ''id'' for each instance. The framework will determine that
by ''registering'' the instance in the all-mighty ''session''.

!!!! Reading instances

We can now read back some of the persisted instances, for that we, again, use
the session object, sending it the message ==#read:== and the class as argument.
This will return a collection of results.

[[[caption=Read all instances of Person|language=smalltalk
session read: Person
]]]

Of course you don't always read all the instances from the database but
want to filter the results. For that you can pass a block that will act as
a filter.

[[[caption=Read all instances of Person matching a criteria|language=smalltalk
session read: Person where: [:each | each firstName = 'John'].
]]]

This might lead you to think you can pass any block to filter the results
as you can do with ==#select:== in a regular Collection, but that is not possible.
Glorp uses blocks as a very clever way to build expressions that
are later converted to SQL by the framework, you can do basic filtering
using this feature, but keep in mind it doesn't work as a regular block.

Besides the use of regular operators like =====, ==>===, etc
One of examples of the mentioned above is the use of ''special'' selectors
that get translated to their counterparts SQL operators.
For instance the ==#similarTo:== selector gets converted to SQL's ==LIKE==
operator. With this we can retrieve all the Persons named ''John''.

[[[caption=Use an operator that gets ''translated''|language=smalltalk
session read: Person where: [:each | each lastName similarTo: 'Malk%'].
]]]

Another convenient way to retrieve a single instance instead of a Collection
is to use the ==#readOneOf:== or ==#readOneOf:where:== message in an analogous
way to ==#read:== and ==#read:where:==.

!!!! Update of instances

We can use this case to read one instance and modify it. But to do so, we will
do it in the context of a UnitOfWork.

[[[caption=Updating an object read within a UnitOfWork
session inUnitOfWorkDo: [
  | person |
  person := session readOneOf: Person where: [:each | each lastName = 'Locke'].
  person birthDate: Date today.
].
]]]

If you read back the 'John Locke' from the database, you'll find that the date
was correctly updated, and it didn't require you to send ==#register:== to the
session object, as we did while populating the table. This is so because when
you're working inside a Unit of Work all the objects you read are automatically
registered by the session, saving you from explicitly ''registering'' them (
  which is safe to do anyway, but it is not required).

!!! Deletion of objects
So far we covered Creation, Read, and Update, we're only missing the Deletion of
objects. Which is as easy as it gets, just send ==#delete:== to the session
object with the object you want to delete as argument.

[[[caption=Deleting an object inside of a UnitOfWork
session inUnitOfWorkDo: [
  | person |
  person := session readOneOf: Person where: [:each | each lastName = 'Locke'].
  session delete: person
].
]]]

Another way to delete objects is passing a condition block.

[[[caption=Delete using a where clause
session inUnitOfWorkDo: [
  session delete: Person where: [:each | each lastName = 'Locke'].
].
]]]

You can delete an object without being inside of a UnitOfWork, this will
cause the object to be deleted right away, without giving you the option
to rollback such action... unless you handle the transaction manually.

!!! Rolling back changes
*Atomic>https://en.wikipedia.org/wiki/Atomicity_%28database_systems%29*
 modifications to the database are important, and to achieve
that you need transactions that let you rollback changes if something fails.
The Unit of Work handles the errors and other unexpected terminations of
the block, so if something fails it not only rollbacks any changes at the
database level if necessary, but also, and more importantly I would say,
it reverts the changes in your objects.

[[[caption=Updating an object read within a UnitOfWork
session inUnitOfWorkDo: [
	person := session readOneOf: Person where: [:each | each lastName = 'Locke'].
	person lastName: 'Wayne'.
	Error signal: 'This error will abort the Unit Of Work.'
].
]]]

!!! Managing the transaction manually
The ==#inUnitOfWorkDo:== is a convenient way to isolate a block of execution
within the context of a transaction at both object and database levels, however
it has some limitations, like not being able to handle ''nested'' UnitOfWorks
or transactions, everything happens in the context of the outer context transaction
in which it was evaluated.

However, if for some reason you need to handle the start/end/rollback of the
unit of work manually, you can do so by using the following methods:

-==#beginUnitOfWork==
-==#commitUnitOfWork==
-==#rollbackUnitOfWork==
-==#commitUnitOfWorkAndContinue==

The first three have self descriptive selectors, and can be using like this:

[[[caption=Manual handling of the transaction
person := session readOneOf: Person where: [:each | each firstName = 'George'].
session beginUnitOfWork.
session delete: person.
session rollbackUnitOfWork.
session beginUnitOfWork.
person lastName: 'Lukas'.
session register: person.
session commitUnitOfWork.
]]]

In the case of ==#commitUnitOfWorkAndContinue== it might need some explanation,
but the concept is simple: It commits the current unit of work, and then
creates a new one migrating all the objects registered in the commited unit of
work to the newly created, and still open, unit of work. If this paragraph
confuses you, looking at its implementation might explain it better.

It is useful for cases like batch loads or updates,
were you want to commit changes every ''n'' instances or similar.

[[[caption=Commiting and continuing the Unit Of Work
session beginUnitOfWork.
10 to: 99 do: [ :index |
   session register: (
		Person new
			firstName: 'Sample';
			lastName: index printString).
	(index \\ 10) isZero ifTrue: [
		session commitUnitOfWorkAndContinue
	].
].
session commitUnitOfWork.
]]]

We can cleanup the sample instances by running:
[[[caption=Delete using a where clause
session inUnitOfWorkDo: [
  session delete: Person where: [:each | each firstName = 'Sample'].
].
]]]


!! Concepts
In our previous example we created a simple class that mapped ''1:1'' with a
table using simple data types, but Glorp provides many more features than
an ''ActiveRecord'' like mapping, it lets you fine tune the persistence of
your classes. We will go over the different configurations of class models,
table data types and constraints and mappings of all sorts.

!!! Class Models
The class model defines the attributes of your domain objects, and how they compose.
Each of your persisted objects need to have a an instance of ==GlorpClassModel==
in the descriptor system containing an a collection of all the attributes of
your class, attributes that by convention are added by means of
implementing ==#classModelForYourClass:==,

The simplest way to add an attribute is using a series of convenience methods,
described below:

;==#newAttributeNamed: #email==
:Used to define simple scalar/literal values such as Numbers, Strings, Dates, etc.
;==#newAttributeNamed: #address type: Address==
:Used to define 1:1 (one to one) relations with other objects of your domain model.
;==#newAttributeNamed: #invoices collectionOf: Invoice==
:Used to define 1:n (one to many) and n:m (many to many) relations of your class model with other models.
;==#newAttributeNamed: #invoices collection: collectionClass of: Invoice==
:Similar as the one above for 1:n and n:m relations, but you can define
what kind of Collection is going to be used.
;==#newAttributeNamed: #counters dictionaryFrom: keyClass to: valueClass==
:Used to define an attribute that is a Dictionary where the key is ==keyClass==
and its values are instances of ==valueClass==.

!!! Attribute properties
The above described methods return instances of ==GlorpAttributeModel==, which
share common properties that you can configure.

;==#useDirectAccess: aBoolean==
:Let you define whether the access to the attribute described by the symbol
of your domain model will be performed by directly accessing the
instance variable (slot) instead of using a standard message send.

;==#beForPseudoVariable==
:Useful for cases where you want to describe an attribute that won't be read
nor written, but still described. E.g. our Person example has a ==#birthDate==
attribute, an ==#age== attribute is a good candidate to be for a pseudo variable.

[[[caption=Example class model for our Person class
GlorpBookDescriptorSystem>>#classModelForPerson: aClassModel
  (aClassModel newAttributeNamed: #id) useDirectAccess: true.
  aClassModel newAttributeNamed: #fistName.
  aClassModel newAttributeNamed: #lastName.
  aClassModel newAttributeNamed: #birthDate.
  (aClassModel newAttributeNamed: #age) beForPseudoVariable.
  aClassModel newAttributeNamed: #email.
  aClassModel newAttributeNamed: #address type: Address.
  aClassModel newAttributeNamed: #invoices collectionOf: Invoice.
  aClassModel newAttributeNamed: #counters from: String to: Integer.
]]]

!!! Table Models
Glorp also models your database objects, such as tables, constraints, indexes,
etc., with this model it will be able to determine how to serialize to SQL
the objects, how to perform joins to retrieve 1:1 or 1:n relations, and so on.

The descriptor system follows a convention to define the tables,
it uses the ==#tableForTABLENAME:== selector to configure ==TABLENAME==, the
argument of this method is an instance of ==DatabaseTable==, and this
method is responsible for describing your table in the relational
database, including field names and their data types, contraints (primary keys
and/or foreign keys), etc.

!!!! Adding fields to the table
Let's bring back our example from the beginning:
[[[caption=Table model for PERSON table
GlorpBookDescriptorSystem>>#tableForPERSON: aTable
 	(aTable createFieldNamed: 'id' type: platform serial) bePrimaryKey.
	aTable createFieldNamed: 'firstName' type: (platform varChar: 100).
  aTable createFieldNamed: 'lastName' type: (platform varChar: 100).
  aTable createFieldNamed: 'birthDate' type: platform date.
]]]

As you can see, you can add a field by sending ==#createFieldNamed:type:== to
the table object. The first argument of the method is name of field
(aka ''column'') in your table, the second one is the datatype.
For the datatype we're not specifying any particular implementation of the type
but instead we send a message to the ''platform'' object, and in Glorp jargon
the platform is the RDBMS we'll be using.

Doing it this way enables our
table model to be RDBMS agnostic, and, for instance,
it will work with SQLite or PostgreSQL (or any other platform).
E.g. if our platform is PostgreSQL then ==platform varchar== will return
==VARCHAR==, but if instead our platform is SQLite then it will return ==TEXT==
because SQLite only supports ==TEXT== as datatype for character based fiedls.

Going back to ==#createFieldNamed:type:==, it will return an instance of
==DatabaseField==, which has properties of its own, such as if the field is
''nullable'', ''unique'', its default value, and some convenience methods such
as ==#bePrimaryKey== which will create a ''PK'' (primary key) on the table
for this field.

!!!!!Commonly used datatypes in alphabetic order
||selector||''SQL-92'' datatype||Pharo class||description
|{ blob |{ BLOB |{ ByteArray |{ Binary Large Objects, used to store binary data
|{ boolean |{ BOOLEAN |{ Boolean |{ Boolean values such as ==true==, ==false==, 1, 0, etc.
|{ date |{ DATE |{ Date |{ Used to store dates, without time information.
|{ decimal |{ NUMERIC |{ ScaledDecimal |{ Arbitrary precision numbers, recommended for storing monetary amounts and other quantities where exactness is required.
|{ double |{ DOUBLE |{ Float |{ Double precision floating point
|{ float |{ REAL |{ Float |{ Simple precision floating point
|{ integer |{ INTEGER |{ Integer |{ Number with no decimal information
|{ serial |{ SERIAL |{ Integer |{ Integer that autoincrements on the database side
|{ time |{ TIME |{ Time |{ Storing hours
|{ timestamp |{ TIMESTAMP |{ DateAndTime |{ Date and time information in UTC
|{ varchar |{ VARCHAR |{ String |{ Variable lenght but limited sequence of characters

You can find more datatypes by browsing the ''types'' method category of
==DatabasePlatform== or any of its subclasses, not all databases support all
datatypes, and some platforms have their own datatype. If you decide to use
a datatype that's only supported by a particular RDBMS you will lose the
benefits of being platform agnostic, so it is a tradeoff.

!!! Mappings

!! Extending our basic example
